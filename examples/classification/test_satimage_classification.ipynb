{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_test import *\n",
    "\n",
    "from sklearn import model_selection\n",
    "from matplotlib.pyplot import *\n",
    "from theano import shared, config\n",
    "import numpy as np\n",
    "\n",
    "from deepensemble.metrics import *\n",
    "from deepensemble.utils import *\n",
    "\n",
    "\n",
    "data_input, data_target, classes_labels, name_db, desc, col_names = load_data('satimage',\n",
    "                                                                              data_home='../../test_models/data', normalize=True)\n",
    "\n",
    "# Generate testing and training sets\n",
    "input_train, input_test, target_train, target_test = \\\n",
    "    model_selection.train_test_split(data_input, data_target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = data_input.shape[1]\n",
    "n_classes = len(classes_labels)\n",
    "\n",
    "n_output = n_classes\n",
    "n_inputs = n_features\n",
    "\n",
    "n_neurons_model = int(0.5 * (n_output + n_inputs))\n",
    "\n",
    "n_ensemble_models = 3\n",
    "fn_activation1 = ActivationFunctions.sigmoid\n",
    "fn_activation2 = ActivationFunctions.sigmoid\n",
    "\n",
    "y = get_index_label_classes(translate_target(data_target, classes_labels))\n",
    "s = ITLFunctions.silverman(shared(np.array(y))).eval()\n",
    "\n",
    "list_scores = [\n",
    "    {'fun_score': mutual_information_parzen, 'name': 'Mutual Information'},\n",
    "    {'fun_score': mutual_information_cs, 'name': 'QMI CS'},\n",
    "    {'fun_score': mutual_information_ed, 'name': 'QMI ED'}\n",
    "]\n",
    "\n",
    "print('Silverman: %0.4g' % s)\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 500\n",
    "n_ensemble_models = 3\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "args_train_default = {'max_epoch': max_epoch, 'batch_size': batch_size, 'early_stop': False,\n",
    "              'improvement_threshold': 0.995, 'update_sets': True, 'minibatch': True}\n",
    "\n",
    "args_train_cip = {'max_epoch': max_epoch, 'batch_size': batch_size, 'early_stop': False,\n",
    "              'improvement_threshold': 0.995, 'update_sets': True, 'minibatch': True,\n",
    "              'criterion_update_params': 'cost', 'maximization_criterion': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Ensemble\n",
    "ensemble = get_ensemble_model(name='Ensamble', classification=True, classes_labels=classes_labels,\n",
    "                              n_input=n_features, n_output=n_output,\n",
    "                              n_ensemble_models=n_ensemble_models, n_neurons_model=n_neurons_model,\n",
    "                              fn_activation1=fn_activation1, fn_activation2=fn_activation2,\n",
    "                              cost=mse, name_cost=\"MSE\",\n",
    "                              params_update={'learning_rate': lr})\n",
    "\n",
    "metrics_ensemble = FactoryMetrics.get_metric(ensemble)\n",
    "\n",
    "# Compile\n",
    "ensemble.compile(fast=True)\n",
    "\n",
    "# training\n",
    "metrics = ensemble.fit(input_train, target_train, **args_train_default)\n",
    "print(\"FINISHED!\")\n",
    "\n",
    "# Compute metricstrain\n",
    "metrics_ensemble.append_metric(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Ensemble NCL\n",
    "ensembleNCL = get_ensembleNCL_model(name='Ensamble NCL', classification=True, classes_labels=classes_labels,\n",
    "                                        n_input=n_features, n_output=n_output,\n",
    "                                        n_ensemble_models=n_ensemble_models, n_neurons_models=n_neurons_model,\n",
    "                                        fn_activation1=fn_activation1, fn_activation2=fn_activation2,\n",
    "                                        lamb=0.8, params_update={'learning_rate': lr})\n",
    "\n",
    "metrics_ensembleNCL = FactoryMetrics.get_metric(ensembleNCL)\n",
    "\n",
    "# Compile\n",
    "ensembleNCL.compile(fast=True)\n",
    "                      \n",
    "# training\n",
    "metrics = ensembleNCL.fit(input_train, target_train, **args_train_default)\n",
    "print(\"FINISHED!\")\n",
    "\n",
    "# Compute metricstrain\n",
    "metrics_ensembleNCL.append_metric(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MLP\n",
    "mlp = get_mlp_model(\"MLP (%d neuronas)\" % (n_neurons_model * n_ensemble_models),\n",
    "                           classification=True, classes_labels=classes_labels,\n",
    "                           n_input=n_features, n_output=n_output,\n",
    "                           n_neurons=n_neurons_model,\n",
    "                           fn_activation1=fn_activation1, fn_activation2=fn_activation2,\n",
    "                           cost=mse, name_cost=\"MSE\", params_update={'learning_rate': lr})\n",
    "\n",
    "metrics_mlp = FactoryMetrics.get_metric(mlp)\n",
    "\n",
    "# Compile\n",
    "mlp.compile(fast=True)\n",
    "                      \n",
    "# training\n",
    "metrics = mlp.fit(input_train, target_train, **args_train_default)\n",
    "print(\"FINISHED!\")\n",
    "\n",
    "# Compute metricstrain\n",
    "metrics_mlp.append_metric(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Ensemble CIP\n",
    "ensembleCIP = get_ensembleCIP_model(name='Ensamble CIPL', classification=True, classes_labels=classes_labels,\n",
    "                                    n_input=n_features, n_output=n_output,\n",
    "                                    n_ensemble_models=n_ensemble_models, n_neurons_models=n_neurons_model,\n",
    "                                    is_cip_full=False,\n",
    "                                    fn_activation1=fn_activation1, fn_activation2=fn_activation2,\n",
    "                                    dist='CS',\n",
    "                                    beta=0.3, lamb=0.3, s=s,\n",
    "                                    lsp=1.5, lsm=0.5,\n",
    "                                    bias_layer=False, mse_first_epoch=True, annealing_enable=True,\n",
    "                                    update=sgd, name_update='SGD',\n",
    "                                    params_update={'learning_rate': -5*lr})\n",
    "\n",
    "metrics_ensembleCIP = FactoryMetrics.get_metric(ensembleCIP)\n",
    "\n",
    "# Compile\n",
    "ensembleCIP.compile(fast=False)\n",
    "                      \n",
    "# training\n",
    "metrics = ensembleCIP.fit(input_train, target_train, **args_train_cip)\n",
    "print(\"FINISHED!\")\n",
    "\n",
    "# Compute metricstrain\n",
    "metrics_ensembleCIP.append_metric(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics_ensembleCIP.plot_scores(max_epoch=max_epoch, title='')\n",
    "metrics_ensembleCIP.plot_cost(max_epoch=max_epoch, title='')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from pylab import *\n",
    "\n",
    "def plot_pdf_error(model, _input, _target, label_plot, ax, fig, n_points=500, xmin=-1.5, xmax=1.5, lim_y=0.08):\n",
    "    error = model.error(_input, model.translate_target(_target)).eval()\n",
    "    N = len(error)\n",
    "    s = 1.06 * np.std(error) / np.power(N, 0.2)  # Silverman\n",
    "    \n",
    "    x_plot = np.linspace(xmin, xmax, n_points)\n",
    "    \n",
    "    plt.hold(True)\n",
    "    for j in range(ensemble.get_fan_out()):\n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=s)\n",
    "        e = error[:, j]\n",
    "        kde.fit(e[:, np.newaxis])    \n",
    "        y = np.exp(kde.score_samples(x_plot[:, np.newaxis]))\n",
    "        ax.plot(x_plot, y / np.sum(y), label='Salida %d' % (j + 1))\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(label_plot)\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('PDF del error')\n",
    "    ax.set_ylim([0, lim_y])\n",
    "    \n",
    "fig = plt.figure(figsize=(10, 7), dpi=80)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "plot_pdf_error(ensemble, input_train, target_train, 'Ensamble', ax, fig)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "plot_pdf_error(ensembleNCL, input_train, target_train, 'Ensamble NCL', ax, fig)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "plot_pdf_error(ensembleCIP, input_train, target_train, 'Ensamble CIP', ax, fig)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4)\n",
    "plot_pdf_error(mlp, input_train, target_train, 'MLP', ax, fig)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "st = fig.suptitle(\"Función de Probabilidad (pdf) del Error\\n conjunto Entrenamiento\", fontsize=18)\n",
    "\n",
    "st.set_y(0.95)\n",
    "fig.subplots_adjust(top=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7), dpi=80)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "plot_pdf_error(ensemble, input_test, target_test, 'Ensamble', ax, fig)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "plot_pdf_error(ensembleNCL, input_test, target_test, 'Ensamble NCL', ax, fig)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "plot_pdf_error(ensembleCIP, input_test, target_test, 'Ensamble CIP', ax, fig)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4)\n",
    "plot_pdf_error(mlp, input_test, target_test, 'MLP', ax, fig)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "st = fig.suptitle(\"Función de Probabilidad (pdf) del Error\\n conjunto de prueba\", fontsize=18)\n",
    "\n",
    "st.set_y(0.95)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_test_ensemble = ensemble.score(input_test, target_test)\n",
    "score_train_ensemble = ensemble.score(input_train, target_train)\n",
    "\n",
    "score_test_ensembleNCL = ensembleNCL.score(input_test, target_test)\n",
    "score_train_ensembleNCL = ensembleNCL.score(input_train, target_train)\n",
    "\n",
    "score_test_ensembleCIP = ensembleCIP.score(input_test, target_test)\n",
    "score_train_ensembleCIP = ensembleCIP.score(input_train, target_train)\n",
    "\n",
    "score_test_mlp = mlp.score(input_test, target_test)\n",
    "score_train_mlp = mlp.score(input_train, target_train)\n",
    "\n",
    "print('Score Precisión')\n",
    "print('Ensamble MSE: %f / %f' % (score_train_ensemble, score_test_ensemble))\n",
    "print('Ensamble NCL: %f / %f' % (score_train_ensembleNCL, score_test_ensembleNCL))\n",
    "print('Ensamble CIP: %f / %f' % (score_train_ensembleCIP, score_test_ensembleCIP))\n",
    "print('MLP: %f / %f' % (score_train_mlp, score_test_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_ensembleCIP.append_prediction(input_test, target_test, append_last_pred=True)\n",
    "metrics_ensembleCIP.plot_confusion_matrix(title='Matriz de Confusión\\nEnsamble CIPL')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_ensembleNCL.append_prediction(input_test, target_test, append_last_pred=True)\n",
    "metrics_ensembleNCL.plot_confusion_matrix(title='Matriz de Confusión\\nEnsamble NCL')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_ensemble.append_prediction(input_test, target_test, append_last_pred=True)\n",
    "metrics_ensemble.plot_confusion_matrix(title='Matriz de Confusión\\nEnsamble MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_mlp.append_prediction(input_test, target_test, append_last_pred=True)\n",
    "metrics_mlp.plot_confusion_matrix(title='Matriz de Confusión\\nMLP')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ensemble_cip_cs(_param, s_sigma, fast=True):\n",
    "    ensemble = get_ensembleCIP_model(name='Ensamble CIP CS',\n",
    "                                    n_input=n_features, n_output=n_output,\n",
    "                                    n_ensemble_models=n_ensemble_models, n_neurons_models=n_neurons_model,\n",
    "                                    classification=True,\n",
    "                                    is_cip_full=False,\n",
    "                                    classes_labels=classes_labels,\n",
    "                                    fn_activation1=fn_activation1, fn_activation2=fn_activation2,\n",
    "                                    dist='CS',\n",
    "                                    beta=_param, lamb=_param, s=s_sigma,\n",
    "                                    lsp=1.5, lsm=0.5,\n",
    "                                    lr=0.1,\n",
    "                                    bias_layer=False, mse_first_epoch=True, annealing_enable=True,\n",
    "                                    update=sgd, name_update='SGD',\n",
    "                                    params_update={'learning_rate': -0.1}\n",
    "                                    )\n",
    "\n",
    "    ensemble.compile(fast=fast)\n",
    "\n",
    "    return ensemble\n",
    "\n",
    "def get_ensemble_cip_ed(_param, s_sigma, fast=True):\n",
    "    ensemble = get_ensembleCIP_model(name='Ensamble CIP ED',\n",
    "                                    n_input=n_features, n_output=n_output,\n",
    "                                    n_ensemble_models=n_ensemble_models, n_neurons_models=n_neurons_model,\n",
    "                                    classification=True,\n",
    "                                    is_cip_full=False,\n",
    "                                    classes_labels=classes_labels,\n",
    "                                    fn_activation1=fn_activation1, fn_activation2=fn_activation2,\n",
    "                                    dist='ED',\n",
    "                                    beta=_param, lamb=_param, s=s_sigma,\n",
    "                                    lsp=1.5, lsm=0.1,\n",
    "                                    lr=0.1,\n",
    "                                    bias_layer=False, mse_first_epoch=True, annealing_enable=True,\n",
    "                                    update=sgd, name_update='SGD',\n",
    "                                    params_update={'learning_rate': -0.5}\n",
    "                                    )\n",
    "\n",
    "    ensemble.compile(fast=fast)\n",
    "\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [n for n in np.linspace(-1, 1, 21)]\n",
    "\n",
    "score_cs = []\n",
    "diversity_cs = []\n",
    "for p in parameters:\n",
    "    model_cs = get_ensemble_cip_cs(p, s)\n",
    "    metric = model_cs.fit(input_train, target_train, **args_train_cip)\n",
    "    score_cs.append(model_cs.score(input_test, target_test))\n",
    "    metric.append_prediction(input_test, target_test, append_last_pred=True)\n",
    "    diversity_cs.append(\n",
    "        (metric.get_diversity(metric=kohavi_wolpert_variance),\n",
    "         metric.get_diversity(metric=generalized_diversity),\n",
    "         metric.get_diversity(metric=coincident_failure),\n",
    "         metric.get_diversity(metric=entropy_sk),\n",
    "         metric.get_diversity(metric=difficulty),\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_ed = []\n",
    "diversity_ed = []\n",
    "for p in parameters:\n",
    "    model_ed = get_ensemble_cip_ed(p, s)\n",
    "    metric = model_ed.fit(input_train, target_train, **args_train_cip)\n",
    "    score_ed.append(model_ed.score(input_test, target_test))\n",
    "    metric.append_prediction(input_test, target_test, append_last_pred=True)\n",
    "    diversity_ed.append(\n",
    "        (metric.get_diversity(metric=kohavi_wolpert_variance),\n",
    "         metric.get_diversity(metric=generalized_diversity),\n",
    "         metric.get_diversity(metric=coincident_failure),\n",
    "         metric.get_diversity(metric=entropy_sk),\n",
    "         metric.get_diversity(metric=difficulty),\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score_cs = np.array(score_cs)\n",
    "diversity_cs = np.array(diversity_cs)\n",
    "score_ed = np.array(score_ed)\n",
    "diversity_ed = np.array(diversity_ed)\n",
    "\n",
    "f = plt.figure(figsize=(7,5), dpi=80)\n",
    "plt.plot(parameters, score_cs, linestyle='-', label='Ensamble CIPL CS')\n",
    "plt.plot(parameters, score_ed, linestyle='--', label='Ensamble CIPL ED')\n",
    "plt.legend()\n",
    "plt.title('Precisión')\n",
    "plt.xlabel('Parámetro')\n",
    "plt.ylabel('Precisión')\n",
    "plt.tight_layout()\n",
    "\n",
    "f = plt.figure(figsize=(7,5), dpi=80)\n",
    "plt.plot(parameters, diversity_cs[:,0, 0], linestyle='-', label='Ensamble CIPL CS')\n",
    "plt.plot(parameters, diversity_ed[:,0, 0], linestyle='--', label='Ensamble CIPL ED')\n",
    "plt.legend()\n",
    "plt.title('Diversidad Kohavi wolpert variance')\n",
    "plt.xlabel('Parámetro')\n",
    "plt.ylabel('Kohavi wolpert variance')\n",
    "plt.tight_layout()\n",
    "\n",
    "f = plt.figure(figsize=(7,5), dpi=80)\n",
    "plt.plot(parameters, diversity_cs[:,1, 0], linestyle='-', label='Ensamble CIPL CS')\n",
    "plt.plot(parameters, diversity_ed[:,1, 0], linestyle='--', label='Ensamble CIPL ED')\n",
    "plt.legend()\n",
    "plt.title('Diversidad Generalized diversity')\n",
    "plt.xlabel('Parámetro')\n",
    "plt.ylabel('Generalized diversity')\n",
    "plt.tight_layout()\n",
    "\n",
    "f = plt.figure(figsize=(7,5), dpi=80)\n",
    "plt.plot(parameters, diversity_cs[:,4, 0], linestyle='-', label='Ensamble CIPL CS')\n",
    "plt.plot(parameters, diversity_ed[:,4, 0], linestyle='--', label='Ensamble CIPL ED')\n",
    "plt.legend()\n",
    "plt.title('Diversidad Difficulty')\n",
    "plt.xlabel('Parámetro')\n",
    "plt.ylabel('Difficulty')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cs = get_ensemble_cip_cs(0.5, s)\n",
    "model_cs.fit(input_train, target_train, **args_train_cip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ed = get_ensemble_cip_ed(0.5, s)\n",
    "model_ed.fit(input_train, target_train, **args_train_cip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = [n for n in np.linspace(0.01, 1, 10)]\n",
    "score_snr_cs = []\n",
    "score_snr_ed = []\n",
    "score_snr_ncl = []\n",
    "score_snr_en = []\n",
    "score_snr_mlp = []\n",
    "SNR = []\n",
    "N = input_test.shape[0]\n",
    "F = input_test.shape[1]\n",
    "mu = 0.2\n",
    "\n",
    "for n in noise:\n",
    "    ne = np.random.randn(N, F) * n + mu\n",
    "    z = input_test + ne\n",
    "    score_snr_cs.append(model_cs.score(z, target_test))\n",
    "    score_snr_ed.append(model_ed.score(z, target_test))\n",
    "    score_snr_ncl.append(ensembleNCL.score(z, target_test))\n",
    "    score_snr_en.append(ensemble.score(z, target_test))\n",
    "    score_snr_mlp.append(mlp.score(z, target_test))\n",
    "    SNR.append(np.var(input_test) / np.var(ne))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(7,5), dpi=80)\n",
    "plt.plot(SNR, score_snr_cs, linestyle='-', label='Ensamble CIPL CS')\n",
    "plt.plot(SNR, score_snr_ed, linestyle='--', label='Ensamble CIPL ED')\n",
    "plt.plot(SNR, score_snr_ncl, linestyle=':', label='Ensamble NCL')\n",
    "plt.plot(SNR, score_snr_en, linestyle='--', label='Ensamble MSE')\n",
    "plt.plot(SNR, score_snr_mlp, linestyle='-.', label='MLP MSE')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Precisión')\n",
    "plt.xlabel('SNR')\n",
    "plt.ylabel('Precisión')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
