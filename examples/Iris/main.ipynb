{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example MLP: Data base Iris\n",
    "\n",
    "In this example it will show how to work the library **deepensemble**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "This is perhaps the best known database to be found in the pattern recognition literature. Fisher's paper is a classic in the field and is referenced frequently to this day. (See Duda & Hart, for example.) The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. \n",
    "\n",
    "- Predicted attribute: class of iris plant.\n",
    "- Number of Instances: 150\n",
    "- Number of Attributes: 4\n",
    "\n",
    "This data differs from the data presented in Fishers article (identified by Steve Chadwick, <spchadwick@espeedaz.net>). The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from theano.sandbox import cuda\n",
    "\n",
    "theano.config.floatX = 'float32'\n",
    "cuda.use('gpu')\n",
    "theano.config.compute_test_value = 'off'\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "data_input    = np.asarray(iris.data, dtype=theano.config.floatX)\n",
    "data_target   = iris.target_names[iris.target]\n",
    "classes_names = iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training MLP\n",
    "\n",
    "The arquitecture of MLP net is a 3 neurons in hidden layer and the output is a vector with 3 elements that represent each class (**one hot encoding**). The cost function is **MSE** and the update funtion is **ADAGRAD**. The 60% of data set it's used for the training set and 40% in the testing set.\n",
    "\n",
    "#### Important: the library deepensemble must be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from deepensemble.models.sequential import Sequential\n",
    "from deepensemble.layers.dense import Dense\n",
    "from deepensemble.utils.cost_functions import *\n",
    "from deepensemble.utils.update_functions import *\n",
    "from deepensemble.utils.regularizer_functions import *\n",
    "from sklearn import cross_validation\n",
    "\n",
    "net1 = Sequential(\"mlp\", \"classifier\", classes_names)\n",
    "net1.add_layer(Dense(n_input=data_input.shape[1], n_output=3, activation=T.tanh))\n",
    "net1.add_layer(Dense(n_output=len(classes_names), activation=T.nnet.softmax))\n",
    "net1.append_cost(mse)\n",
    "net1.append_reg(L1, lamb=0.005)\n",
    "net1.append_reg(L2, lamb=0.001)\n",
    "net1.set_update(adagrad, initial_learning_rate=0.1)\n",
    "net1.compile()\n",
    "\n",
    "max_epoch = 400\n",
    "validation_jump = 5\n",
    "\n",
    "input_train, input_test, target_train, target_test = cross_validation.train_test_split(\n",
    "        data_input, data_target, test_size=0.3, random_state=0)\n",
    "\n",
    "metrics = net1.fit(input_train, target_train,\n",
    "                                max_epoch=max_epoch, batch_size=32, improvement_threshold=0.5)\n",
    "# Compute metrics\n",
    "metrics.append_prediction(target_test, net1.predict(input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "metrics.classification_report()\n",
    "metrics.plot_confusion_matrix()\n",
    "metrics.plot_cost(max_epoch, \"Cost training\")\n",
    "metrics.plot_score(max_epoch, \"Accuracy training data\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
