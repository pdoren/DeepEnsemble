{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from theano import config\n",
    "\n",
    "a = 5 \n",
    "b = 2\n",
    "N = 2000\n",
    "s_noise = 0.02\n",
    "\n",
    "x0 = np.linspace(-3.0, 3.0, num=N);\n",
    "x1 = np.sin(b * x0)\n",
    "x2 = np.cos(a * x0)\n",
    "\n",
    "fx = 0.1 * x2 + 0.1 *x1 + 0.4\n",
    "\n",
    "fx_str = '$f(x)=cos({%g x}) + sin({%g x})$' % (a, b)\n",
    "\n",
    "nu = np.random.randn(N,) * s_noise\n",
    "# nu[np.random.rand(N,) > 0.95] += 0.2\n",
    "\n",
    "z = fx + nu\n",
    "\n",
    "n_train = int(N * 0.5)\n",
    "i_test = N - n_train\n",
    "\n",
    "X = np.array([x0, x1, x2]).T\n",
    "\n",
    "# X = (X - np.mean(X, axis=0)) / np.var(X, axis=0)\n",
    "\n",
    "y_train = z[0:n_train][:,np.newaxis]\n",
    "y_test = z[i_test:N][:,np.newaxis]\n",
    "X_train = X[0:n_train]\n",
    "X_test = X[i_test:N]\n",
    "\n",
    "fx_train = fx[0:n_train][:,np.newaxis]\n",
    "fx_test = fx[i_test:N][:,np.newaxis]\n",
    "\n",
    "SNR = np.mean(z) / np.std(z)\n",
    "\n",
    "print('SNR: %g' % SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6), dpi=80)\n",
    "ax = plt.subplot(211)\n",
    "ax.plot(X_train[:,0], y_train, 'b.', alpha=0.25, label='Observaciones')\n",
    "ax.plot(X_train[:,0], fx_train, '-r', lw=3, label=fx_str)\n",
    "plt.title('Muestras Entrenamiento')\n",
    "plt.xlabel('x')\n",
    "plt.legend(loc='best', numpoints=3)\n",
    "plt.tight_layout()\n",
    "\n",
    "ax = plt.subplot(212)\n",
    "ax.plot(X_test[:,0], y_test, 'b.', alpha=0.25, label='Observaciones')\n",
    "ax.plot(X_test[:,0], fx_test, '-r', lw=3, label=fx_str)\n",
    "plt.title('Muestras para Pruebas')\n",
    "plt.xlabel('x')\n",
    "plt.legend(loc='best', numpoints=3)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../../../'))\n",
    "\n",
    "from deepensemble.utils.utils_functions import ActivationFunctions\n",
    "from deepensemble.models.sequential import Sequential\n",
    "from deepensemble.layers.dense import Dense\n",
    "from deepensemble.layers.recurrent import RecurrentLayer\n",
    "from deepensemble.models.ensemblemodel import EnsembleModel\n",
    "from deepensemble.combiner import *\n",
    "from deepensemble.metrics import *\n",
    "from deepensemble.utils import *\n",
    "\n",
    "n_neurons = 12\n",
    "n_models = 4\n",
    "lr = 0.005\n",
    "batch_size = 50\n",
    "max_epoch = 300\n",
    "\n",
    "n_ensemble_models = 5\n",
    "\n",
    "fn_activation1 = ActivationFunctions.tanh\n",
    "fn_activation2 = ActivationFunctions.sigmoid\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "n_output = y_train.shape[1]\n",
    "n_inputs = n_features\n",
    "\n",
    "n_neurons_model = int(0.75 * (n_output + n_inputs))\n",
    "\n",
    "s = ITLFunctions.silverman(np.array(y_train)).eval()\n",
    "print('Silverman: %0.4g' % s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Ensemble\n",
    "ensemble = get_ensemble_model(name='Ensamble',\n",
    "                                  n_input=n_features, n_output=n_output,\n",
    "                                  n_ensemble_models=n_ensemble_models, n_neurons_model=n_neurons_model,\n",
    "                                  fn_activation1=fn_activation1, fn_activation2=fn_activation2,\n",
    "                                  cost=mse, name_cost=\"MSE\",\n",
    "                                  params_update={'learning_rate': lr})\n",
    "\n",
    "metrics_ensemble = FactoryMetrics.get_metric(ensemble)\n",
    "\n",
    "# Compile\n",
    "ensemble.compile(fast=True)\n",
    "\n",
    "# training\n",
    "metrics = ensemble.fit(X_train, y_train, max_epoch=max_epoch, batch_size=batch_size, early_stop=False)\n",
    "print(\"FINISHED!\")\n",
    "\n",
    "# Compute metricstrain\n",
    "metrics_ensemble.append_metric(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Ensemble NCL\n",
    "ensembleNCL = get_ensembleNCL_model(name='Ensamble NCL',\n",
    "                                        n_input=n_features, n_output=n_output,\n",
    "                                        n_ensemble_models=n_ensemble_models, n_neurons_models=n_neurons_model,\n",
    "                                        fn_activation1=fn_activation1, fn_activation2=fn_activation2,\n",
    "                                        lamb=0.8, params_update={'learning_rate': lr})\n",
    "\n",
    "metrics_ensembleNCL = FactoryMetrics.get_metric(ensembleNCL)\n",
    "\n",
    "# Compile\n",
    "ensembleNCL.compile(fast=True)\n",
    "                      \n",
    "# training\n",
    "metrics = ensembleNCL.fit(X_train, y_train, max_epoch=max_epoch, batch_size=batch_size, early_stop=False)\n",
    "print(\"FINISHED!\")\n",
    "\n",
    "# Compute metricstrain\n",
    "metrics_ensembleNCL.append_metric(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create MLP\n",
    "mlp = get_mlp_model(\"MLP (%d neuronas)\" % (n_neurons_model * n_ensemble_models),\n",
    "                           n_input=n_features, n_output=n_output,\n",
    "                           n_neurons=n_neurons_model,\n",
    "                           fn_activation1=fn_activation1, fn_activation2=fn_activation2,\n",
    "                           cost=mse, name_cost=\"MSE\", params_update={'learning_rate': lr})\n",
    "\n",
    "metrics_mlp = FactoryMetrics.get_metric(mlp)\n",
    "\n",
    "# Compile\n",
    "mlp.compile(fast=True)\n",
    "                      \n",
    "# training\n",
    "metrics = mlp.fit(X_train, y_train, max_epoch=max_epoch, batch_size=batch_size, early_stop=False)\n",
    "print(\"FINISHED!\")\n",
    "\n",
    "# Compute metricstrain\n",
    "metrics_mlp.append_metric(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Ensemble CIP\n",
    "ensembleCIP = get_ensembleCIP_model(name='Ensamble CIP',\n",
    "                                    n_input=n_features, n_output=n_output,\n",
    "                                    n_ensemble_models=n_ensemble_models, n_neurons_models=n_neurons_model,\n",
    "                                    is_cip_full=True,\n",
    "                                    fn_activation1=fn_activation1, fn_activation2=fn_activation2,\n",
    "                                    dist='ED',\n",
    "                                    beta=0.3, lamb=0.3, s=s,\n",
    "                                    lsp=1.5, lsm=0.1,\n",
    "                                    bias_layer=False, mse_first_epoch=False, annealing_enable=True,\n",
    "                                    update=sgd_momentum, name_update='SGD',\n",
    "                                    params_update={'learning_rate': -lr})\n",
    "\n",
    "metrics_ensembleCIP = FactoryMetrics.get_metric(ensembleCIP)\n",
    "\n",
    "# Compile\n",
    "ensembleCIP.compile(fast=True)\n",
    "                      \n",
    "# training\n",
    "metrics = ensembleCIP.fit(X_train, y_train, max_epoch=max_epoch, batch_size=batch_size, early_stop=False,\n",
    "                         criterion_update_params = 'cost', maximization_criterion=True)\n",
    "print(\"FINISHED!\")\n",
    "\n",
    "# Compute metricstrain\n",
    "metrics_ensembleCIP.append_metric(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6), dpi=80)\n",
    "\n",
    "t = X_train[:,0]\n",
    "plt.subplot(211)\n",
    "plt.plot(x0, z, 'k.', alpha=0.15,  label='Muestras')\n",
    "plt.plot(t, ensemble.predict(X_train), lw=2, label='Ensamble')\n",
    "plt.plot(t, ensembleNCL.predict(X_train), lw=2, label='Ensamble NCL')\n",
    "plt.plot(t, ensembleCIP.predict(X_train), lw=2, label='Ensamble CIP')\n",
    "plt.plot(t, mlp.predict(X_train), lw=2, label='MLP')\n",
    "plt.title('Conjunto Entrenamiento - %s' % fx_str)\n",
    "plt.xlabel('x')\n",
    "plt.xlim([-3,3])\n",
    "plt.ylim([-0.5,1.1])\n",
    "plt.legend(loc='best', ncol=5)\n",
    "\n",
    "\n",
    "t = X_test[:,0]\n",
    "plt.subplot(212)\n",
    "plt.plot(x0, z, 'k.', alpha=0.15, label='Muestras')\n",
    "plt.plot(t, ensemble.predict(X_test), lw=2, label='Ensamble')\n",
    "plt.plot(t, ensembleNCL.predict(X_test), lw=2, label='Ensamble NCL')\n",
    "plt.plot(t, ensembleCIP.predict(X_test), lw=2, label='Ensamble CIP')\n",
    "plt.plot(t, mlp.predict(X_test), lw=2, label='MLP')\n",
    "plt.title('Conjunto Prueba - %s' % fx_str)\n",
    "plt.xlabel('x')\n",
    "plt.xlim([-3,3])\n",
    "plt.ylim([-0.5,1.1])\n",
    "plt.legend(loc='best', ncol=5)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors.kde import KernelDensity\n",
    "\n",
    "def plot_pdf_error(pred, target, label_plot, ax, fig, n_points=1000, xmin=-3, xmax=3):\n",
    "    error = pred - target\n",
    "    N = len(error)\n",
    "    s = 1.06 * np.std(error) / np.power(N, 0.2)  # Silverman\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=0.2)\n",
    "    kde.fit(error)\n",
    "    x_plot = np.linspace(xmin, xmax, n_points)[:, np.newaxis]\n",
    "    y_plot = np.exp(kde.score_samples(x_plot))\n",
    "    ax.plot(x_plot, y_plot / np.sum(y_plot), label=label_plot)\n",
    "    \n",
    "fig = plt.figure(figsize=(10, 5), dpi=80)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "plot_pdf_error(ensemble.predict(X_train), y_train, 'Ensamble', ax, fig)\n",
    "plot_pdf_error(ensembleNCL.predict(X_train), y_train, 'Ensamble NCL', ax, fig)\n",
    "plot_pdf_error(ensembleCIP.predict(X_train), y_train, 'Ensamble CIP', ax, fig)\n",
    "plot_pdf_error(mlp.predict(X_train), y_train, 'MLP', ax, fig)\n",
    "\n",
    "plt.xlabel('Error')\n",
    "plt.ylabel('PDF del error');\n",
    "plt.title(\"Función de Probabilidad (pdf) del Error conjunto Entrenamiento\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5), dpi=80)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "plot_pdf_error(ensemble.predict(X_test), y_test, 'Ensamble', ax, fig)\n",
    "plot_pdf_error(ensembleNCL.predict(X_test), y_test, 'Ensamble NCL', ax, fig)\n",
    "plot_pdf_error(ensembleCIP.predict(X_test), y_test, 'Ensamble CIP', ax, fig)\n",
    "plot_pdf_error(mlp.predict(X_test), y_test, 'MLP', ax, fig)\n",
    "\n",
    "plt.xlabel('Error')\n",
    "plt.ylabel('PDF del error');\n",
    "plt.title(\"Función de Probabilidad (pdf) del Error conjunto Entrenamiento\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "score_test_ensemble = ensemble.score(X_test, y_test)\n",
    "score_train_ensemble = ensemble.score(X_train, y_train)\n",
    "\n",
    "score_test_ensembleNCL = ensembleNCL.score(X_test, y_test)\n",
    "score_train_ensembleNCL = ensembleNCL.score(X_train, y_train)\n",
    "\n",
    "score_test_ensembleCIP = ensembleCIP.score(X_test, y_test)\n",
    "score_train_ensembleCIP = ensembleCIP.score(X_train, y_train)\n",
    "\n",
    "score_test_mlp = mlp.score(X_test, y_test)\n",
    "score_train_mlp = mlp.score(X_train, y_train)\n",
    "\n",
    "print('Score RMS')\n",
    "print('Ensamble: %f / %f' % (score_train_ensemble, score_test_ensemble))\n",
    "print('Ensamble NCL: %f / %f' % (score_train_ensembleNCL, score_test_ensembleNCL))\n",
    "print('Ensamble CIP: %f / %f' % (score_train_ensembleCIP, score_test_ensembleCIP))\n",
    "print('MLP: %f / %f' % (score_train_mlp, score_test_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
